# 렌터카 보험사기 판별

- 문제정의
  - '뒷쿵' 자동차 보험사기 19년 기준 피해액 8090억원 추정
  - 특히 렌터카업체가 보험사기 주요타겟이 되고 있다
    - 렌터카사고는 가해자 자차보험료에는 영향을 주지 않기 때문
  - 머신러닝을 사용하여 보험사기 문제를 해결한다
  - 평가지표는 accuracy, precision, recall 세 가지 지표로 구성
    - 클래스불균형이 심해서 accuracy 하나만으로 평가할 수 없기 때문
- 데이터수집
  - 렌터카업체 '쏘카' 사내데이터 제공
  - 16,000rows \* 25columns
- 데이터처리&분석
  - 스케일링
    - 대체적으로 성능 향상에 도움이 되지는 않았다
    - robust 스케일링 선택
      - robust 스케일링이란?
        - minmax 스케일링과 유사하나 minmax 대신 IQR을 사용
        - 이상치가 있는 데이터에 효과적이다
  - 리샘플링
    - 클래스불균형
      - fraud_true: 41(0.3%)
      - fraud_false: 15,959(99.7%)
  - 언더샘플링
    - 대체적으로 성능 향상에 도움이 되지는 않았다
    - 데이터 정보손실이 성능저하를 유도했을 것으로 추론
    - 소수클래스 데이터가 41개 밖에 없으므로 적합하지 않은 것으로 판단
  - 오버샘플링
    - 대체적으로 성능 향상에 도움이 되었다
    - 성능이 가장 좋았던 BorderlineSMOTE 오버샘플링 선택
    - BorderlineSMOTE 오버샘플링이란?
      - knn방식으로 비슷한 가상데이터 생성하는 SMOTE와 유사
      - 다만 데이터 사이 무작위 생성이 아닌 클래스 사이 결정경계를 따라 생성
      - 해당 과정을 소수클래스 모든 데이터에 대해 반복수행
    - 과적합 확률이 높아질 수 있으므로 교차검증이 중요할 것으로 추론
  - 기타
    - 결측치 50% 이상인 컬럼 -> drop
    - Nominal data -> 원핫인코딩
    - Ordinal data -> 올바른 순서로 수정
  - 피처셀렉션
    - feature importance 기반
- 분석결과
  - accuracy, precision 모두 성능향상에 성공
    - Baseline
      - accuracy 0.493, precision 0.003, recall 0.714
    - Model
      - accuracy 0.964, precision 0.043, recall 0.714
  - 모델에 의한 보험사기범 프로필은 다음과 같다
    - 수리비용 1,944원 미만
    - 자기부담금 5만원(보험가입)
    - 대여시작시간 5pm-4am
    - 파손부위 1개 이하
    - 대체적으로 경미한 사고 & 어두운 시간이라는 특징을 발견
  - precision vs recall
    - precision: 예측true 중 실제true 비율
    - recall: 실제true 중 예측ture 비율
    - 낮은 precision & 높은 recall
      - 서비스 만족도가 내려갈 수 있다
        - 사기가 아닌 사용자를 사기라고 의심할 확률이 높다
      - 보험사기를 잡을 수 있는 확률이 높다
    - 높은 precision & 낮은 recall
      - 서비스 만족도가 올라갈 수 있다
        - 사기가 아닌 사용자를 사기라고 의심할 확률이 낮다
      - 보험사기를 잡을 수 있는 확률이 낮다
  - precision은 왜 개선되지 않았을까?
    - 데이터 라벨링이 잘못되었을 확률은 없을까?
    - '쏘카'에 문의해보니 사기가 밝혀진 것에 한하여 라벨링이 되었다고 한다
    - 렌터카업체에 불리한 법적시스템으로 인하여 미신고 사례가 많을 수 있다고 추론
  - 적절한 튜닝으로 과적합을 예방할 수 있다
    - 특히 tree모델은 max_features가 일반화하는 데 큰 도움이 된다
  - 교차검증 순서를 유의해야한다
    - CV after 오버샘플링
      - 대체적으로 성능이 좋아진다
      - overoptimism 발생
        - train & test에 오버샘플링 데이터가 들어간다
        - 그러므로 굉장히 유사한 데이터가 함께 들어갈 수 있다
    - CV during 오버샘플링
      - 대체적으로 성능이 떨어진다
      - overoptimism 방지
        - test에 오버샘플링 데이터가 들어가지 않는다
